\chapter{Introduction}

\newcommand{\question}[1]{\textit{#1}}

\newcommand{\comment}[1]{{#1}}


\section{Why - An Itemized Justification}

\begin{itemize}
    \item AI systems can be dangerous, not only at an ethical level
    \item AI systems can be very complex.
    \item Governance can only be achieved by framing and understanding a system.~\cite{doi:10.1145/3278721.3278745}
    \item Communication with computers is formal.
    \item Formal languages are not yet descriptive and resilient to humans, and efficient for computers.
    \item A new descriptive and efficient language would better ensure that AI systems are not dangerous to humans.
\end{itemize}



\textbf{Research Question 1}: How would it be a human-oriented descriptive language used for communication with computers?


\textbf{Research Question 2}: How could ethical values be encoded in such a language?


\textbf{Research Question 3}: How should an ethical verification system integrate that language?

\subsection{AI Systems risks}

AI systems can outperform single or multiple human beings in specific tasks, like massively performed facial recognition.
If they are used indulgently, they can threaten human well-being.

\footnote{\url{https://www.cser.ac.uk/research/risks-from-artificial-intelligence/}}
\footnote{\url{https://futureoflife.org/open-letter-autonomous-weapons/}}.
\footnote{\url{https://builtin.com/artificial-intelligence}}

Please observe that we are not considering the risks as consequences of the so-called Artificial General Intelligence.
We consider that the technological gap to reach that point is considerably large and the degree of speculation needed makes it difficult to develop a scientifically solid statement.

\subsection{AI Systems complexity}

Even it is difficult to define precisely what AI means, it is commonly accepted in the literature that they are complex systems.

The problem here is that it is difficult to find a crystal-clear definition of Artificial Intelligence.
Some people would think of the \textit{new} artificial intelligence as machine learning, which is not only wrong, but also not conducive to a \textit{more accurate} definition.
For now, and in the context of this report, AI is either one of two things:
\begin{itemize}
    \item a very complex computer system
    \item whatever hasn't been done yet. (Larry Tesler's theorem)
\end{itemize}

\subsection{Governance of AI Systems}

This means that it is not enough to have an `off-switch'.
Governance can only be achieved when a system is properly understood by those using it.

When a customer buys a product, and the package is transparent, the customer has more trust than when it is opaque and just has a nice picture.
The same happens with a system.
It is good if a recognized expert validates how a system works, but it is a lot better if its users can see it by themselves.
Transparency together with governance are not `nice-to-have' properties in a trustable system, they are `must-have' properties instead.

\subsection{Communication with computers}

It does not matter how beautiful and human-friendly a graphic interface can look,
the communication with a system is through a sequence of 0's and 1's that are interpreted by the computer.
In other words, the human understanding of an approximate explanation does not apply to computers.
They simulate it, but in the end, everything inside is 0's and 1's.

\comment{
    This is very difficult to \textit{prove}.
    Papers that mention \textit{communication} usually is about \textit{communication protocols} or similar topics.
    This is almost completely unrelated to the human-computer communication.
    There is also Human-Computer Interaction, which focuses on user interfaces (UI) and user experiences (UX).
    However, every interaction is translated to a sequence of events or commands, which can be perfectly described by a computer language.
}

\subsection{Formal languages}

\begin{itemize}
    \item Why is it hard for people to understand other people's code?
    \item Why do people write comments in natural language next to the source code?
    \item Why do developers need debugging tools at all?
    \item Why cannot most of the people read code as they read a newspaper?
\end{itemize}
The answer to the above questions is simple: source code is not easy to read\cite{Casalnuovo2019}.
Source code needs to be learned, needs to be practiced, and even with many years, pieces of code can be deceiving.
\footnote{\url{https://www.quora.com/What-are-the-biggest-problems-with-modern-programming-languages}}

It seems that some programming languages are designed to simplify its parsing by computers, and not for other humans.

This can be since the beginning of computing.
Languages like Fortran, APL, Cobol, and Lisp sought a simplified communication in some sense.
Fortran is to write mathematical formulas, APL is highly symbolic and minimalistic, Cobol looks like writing English sentences, Lisp is algebraic.
A long list of programming languages, can prove how hard it is to express things clearly.

Python is probably one of the most popular languages in the direction of achieving being both descriptive and useful.

\comment{
    This is a difficult topic.
    How can I make something better without saying that what is done is worse?
    The answer: every language has its own domain.
    It is difficult to criticize programming languages with long trajectory.
    It is better to give a context for their application.

    \begin{tabular}{lll}
        C
        & pro: efficient and long running                          \\
        & con: difficult to maintain, code can be unreadable       \\
        Python
        & pro: fast prototyping                                    \\
        & con: one never knows where it crashes                    \\
        Java
        & pro: reliable engineering                                \\
        & con: verbose and difficult to read                       \\
        Scala
        & pro: highly flexible and elegant                         \\
        & con: things can be written in a completely illegible way \\
    \end{tabular}

    The list can continue, but how to prove that \textit{none} of the developed languages is \textit{good enough}?
    The answer: by clustering them in groups sharing similar issues.
    The clusters are:
    \begin{itemize}
        \item Dynamically typed languages
        \item Imperative language with mutable values
        \item Highly verbose languages
        \item Languages with very limited expressive power
        \item Languages without classes
        \item Languages without lambda expressions
        \item Non-portable languages
        \item Languages without prototyping
    \end{itemize}

    These clusters capture almost all (if not all) mainstream programming languages, and most of unimplemented formal languages.

    The individual justification of each of the points goes in a different section.
    Some are rather easy (dynamically typed languages). Other are not that easy (highly verbose languages) because they rely in a perception of quality (how much is too much?) rather in an objective principle.

    There are languages that can be distinguished inspirations:
    \begin{itemize}
        \item Coq: because it can create a program and prove its correctness, which competes with the human checking, and it complements with it.
        Its code can be exported to Haskell.
        \item Idris: because it is a Haskell dialect based on dependent types.
        Its programs can be made more reliable than standard Haskell.
        \item Haskell: because it is a long-running functional language, with a large community.
        It is a de-facto standard in functional languages.
        \item Closure: because it is Lisp dialect that runs on the JVM.
        \item Prolog: because it is highly minimalistic.
        It is language with long trajectory, and widely accepted in the scientific community.
        \item Scala: because it is concise, flexible, and seamlessly integrates object orientation with functional programming.
        \item Python: because it is becoming the de-facto standard language in teaching.
        Many young students start with Scratch\footnote{\url{https://scratch.mit.edu/}}, but there is a natural transition to Python. In practice many people will understand Python before any other computer language.
    \end{itemize}

    An important observation that needs to be answered is why relying on humans to understand a program.
    Python is highly readable, and might be a global standard in 10 years, but there is very little verification on the code before it is already running.
    Coq, on the other side, is a little more difficult to read, but the compiler can check a proof for the code, and it even can be exported to functional languages.
    The new language has to have a readability comparable to Python, but the compiler has to help proving its correctness as much as possible.

    For comparison, a human would not normally check whether a spreadsheet software performs the mathematical operations correctly.
    The human would check that the calculations are done using the right cells with the right operations.
}

\subsection{A New Language}

A new language is needed, something descriptive and efficient enough.
In this context, `efficient' does not necessary mean that is faster than C, for example.
We mean that its execution or evaluation time is in a human scale.
In other words, a human needs to be able to follow what it is written, and determine whether it is right or wrong.
This does not mean that a computer cannot help, but it means that a computer is not needed to understand its operation.
This language needs a way of using it.
This is discussed in the corresponding section.


\section{Why a Language}

A system can check that an AI system is following ethical principles.

The encoding of ethical values and principles should be reachable to those affected.
If ethical values are encoded in a very complex formalisms, they are not reachable to the affected humans, and could be highly error prone.

The purpose of the language is to have formal specifications that can be \textbf{easily understood by a human reader}, and can be immediately prototyped.
This is used to verify if ethical values are properly encoded in a verification system.

Human-centered specifications are intended to be clearly understood by humans.
Please note that this is not necessarily the most abstract form of specification, since a very abstract specification could be hard to understand even for the intended reader.

As a rule of thumb, the \textbf{intended reader} for this language is a human that can read a formal specification, probably a second-year undergraduate student of a scientific or engineering course of studies.

There is a marked distinction between the reader and the writer.
In standard formalisms, it is common to find that the gap from reading to writing in that formalism can be small or even trivial.

This is not necessarily the case in the language we are presenting.
The language needs to be very easily understood, although not necessarily very easily written.

The \textbf{intended writer} is then an experienced technician that can model ethical values using the provided constructs, but producing a highly readable description.


\section{Properties for the Language}

This section discusses what kind of language is needed.

The following is a list of properties required for a useful specification language for ethical problems.

\begin{itemize}
    \item Formal semantics
    \item Consistency
    \item Decidability
    \item Unary predicates, properties or types
    \item Relations or binary predicates
    \item Logical connectors
    \item Distinction and counting
    \item States or time
    \item Specific domains
\end{itemize}


\section{At-most requirements}

\subsection{Formal semantics}

(filter $\leq $)

A formal semantics is intended to give meaning to the language.
This could be used not only to present to humans, but also to prove formal properties on the language.
This allows for rewriting, to have consistency checking and/or formal verification.

(This discards most of the informally developed programming languages.)

\subsection{Consistency}

(filter $\leq $)

The language has to produce consistent specifications.
Consistency is a key property to ensure that a system really follows what is has been specified.
In other words, if a specification is not consistent, it is not usable.

Please note that this requires that descriptions are \textbf{well-defined}.
Some programming languages handle undefined values poorly, letting a program throw an exception when this occurs, instead of preventing it from happening in the first place.

(This property is maybe obvious, but discards unusable formal languages.)

\subsection{Decidability}

(filter $\leq $)

Decidability is intended to ensure that an answer exists and it is computable.
This comes, of course, to a gray area, since decidability has a high price tag by reducing expressiveness.
Thus, the requirement is to have a language with a well-defined useful decidable fragment.


\section{At-least requirements}

\subsection{Unary predicates, properties or types}

(filter $\geq $)

Predicates and properties are a very natural way of expressing ideas.
If a formal language does not have them, it becomes more intricate to read.

(This discards low-expressive formalisms, like propositional logic.)

\subsection{Logical connectors}

(filter $\geq $)

The language should include some logical connectors used in natural languages.
Things like \textit{and}, \textit{or}, \textit{not} should be able to be expressed in a direct way.

(This discards many decidable fragments of FOL, like lightweight description logics. )

\subsection{Distinction and counting}

(filter $\geq $)

Expressing distinction is a simple way to count.
Without distinction, there is no way to say ``at least 3 elements''.

Even if it is possible, some formalisms do not provide constructs to do it.
In other words, to say that a set has at least 3 elements, we need to explicitly mention $a, b, c$, and then state
$\{a, b, c\} \subseteq A$, $a \neq b$, $a \neq c$, $b \neq c$.

This grows quadratically in the number of elements.
This is not human friendly, and a construct should be provided, something like $size(A) \geq 3$

(This discards formalisms without counting.)

\subsection{Relations or binary predicates}

(filter $\geq $)

Relating objects is necessary to express basic ideas.
For example, to express that something belongs to someone, it is necessary to relate two elements.
An alternative would be creating separate predicates for each object or for each owner.
This grows linearly in the number of properties (for objects or owners) and it is not human friendly.

(This discards formalisms without relations.)

\subsection{States or time}

(filter $\geq $)

It should be possible to reflect the conceptual idea of time and a sequence.
This means that things happen in a certain order, there is a \textit{before} and an \textit{after}.
In addition, in these transitions, there are \textit{states} associated.
This is a human way of understanding \textit{how things go}.

(This discards formalisms without states.)

\subsection{Specific domains}

(filter $\geq $)

It should be possible to describe things going without modelling them completely.
This means, for example, using operations with floating point, without specifying how floating point works.
When modelling problems, it is reasonable to assume that underlying types would work as expected.

(This discard formalisms that cannot use specific domains / concrete domains.)


\section{State of the Art - Why \Soda}

This is a justification of how \Soda was designed.

This justification is developed resembling a derivation.

The purpose of \Soda is to give more control to humans on what computers do.

This is part of concepts like \textbf{transparency} and \textbf{governance}.

Transparency comes when the user is aware of what a system is doing.

Some parts of the programming of a system are beyond the understanding and interest of most humans.
However, it is necessary in critical parts that humans need to completely understand their functioning.

Currently, this is achieved using different tools and techniques.
These include diverse types of tests, best practices, optimal architecture designs, and other rituals to preserve a system under a human control.

\Soda is a language that intends to be easy for and close to humans.
This language is intended to be simple and direct.
Because of that, this language can be considered a \textbf{specification language} or a \textbf{description language}.

Several formalisms are suitable for this task.
The following list is a comprehensive list of categories, although this list is not necessarily exhaustive.
\begin{itemize}
    \item Controlled natural languages, like Attempto Controlled English.
    \item Families of non-classical logics, like modal logics, multi-modal logics, hybrid logics, description logics, epistemic logics, and temporal logics.
    \item First-order logic.
    \item Specification languages for software engineering, like Zed.
    \item Theorem proving assistants, like Coq and Isabelle.
    \item Descriptive programming languages, like Prolog, SmallTalk, Python, and their dialects.
    \item Functional programming languages, like Haskell, Scala, Lisp, and their dialects.
\end{itemize}

Each category has advantages and disadvantages, and can model different aspects of a system.

One of the first properties we want is that a message written with the language has to be \textbf{unambiguous for a human}, either describing formulas or relations.
While a sentence in a controlled natural language is unambiguous for a computer, it could have some shades of ambiguity for humans.
The same challenges that writing a formal text has, are present in a controlled language specification.

In addition, some specifications are better described with mathematical formulas than reciting those formulas.
Natural languages produce confusion in some people, since the common use is not necessarily consistent.
For example, the fallacy ``$p \to q$ then $\lnot p \to \lnot q$'' is unfortunately very common.

In a specification, we want to \textbf{describe qualities and quantities in a natural way}.
We want to describe relations between them.
Non-classical logics are very good to describe qualities, but they can have some limitations to describe quantities.
This does not mean that it is impossible, but rather unusual, needing to tailor a logic for each particular problem.
Decidable fragments of non-classical logics can, however, \textbf{verify consistency} in a specification.
This property is also desirable in the specification language.

Another property is the possibility of \textbf{prototyping the specification}.
We want that the specification can be \textit{run} in some sense.
This is very useful to test what the specification says, for example.
It also lets the user create tests that work as examples of what the specification should model.

First-order logic is with no doubt a powerful tool and it is \textbf{universally understood}.
However, it is not simple to produce a program that satisfies a specification.
The power of first-order logic backfires when a human is not aware of its limitations to prototype their specification.
The semi-decidability of first-order logic is then problematic to automatically generate a prototype.

The Z Specification Language combines the good properties of first-order logic and set theory.
While this language is more suited for certain types of projects, prototyping is still not straight forward.

Theorem proving assistants, like Coq and Isabelle, are excellent tools to model and prove small theorems.

Some very descriptive languages like SmallTalk and Python are dynamically typed.
That means that type inconsistencies could be found when the program is already running.
Python has an imperative approach which can carry in the source code some common errors made in imperative languages, like undetectable side effects or unsafe thread execution.

Prolog is maybe one of the most innovative programming languages.
It is descriptive, but it is dynamically typed. In addition, it has a single data type, the term, and subtypes atoms, numbers, variables, and compound terms.\footnote{\url{https://en.wikipedia.org/wiki/Prolog_syntax_and_semantics}}
Prolog uses the cut (!) symbol to operate, and its execution can sometimes become difficult to follow.

Functional languages are then the best candidates to consider.
Lisp and its dialects, like Clojure and Racket, have still some limitations regarding modelling.
One of the disadvantages in Lisp is the absence of types.
This issue is addressed in Racket\footnote{https://racket-lang.org}.
Another disadvantage of Lisp is the technological gap that needs to be breached when integrating it with the most used technology.
This issue is addressed in Clojure\footnote{https://clojure.org}, which is integrated with the Java Virtual Machine.
The abundance of structures with parentheses hinders readability, but it could be suitable for a skilled technician.

Another important functional language is Haskell.
It is one of the most used and most influential functional languages.
Haskell allows writing clean, descriptive, statically typed code.
Its readability is very good and it is easy to write formulas in it.

The only missing piece in Haskell is the definition of objects, although modules are available for a similar purpose.
In the word of Haskell programmers, object-oriented methods are a \textit{syntactic sugar}.
However, the source code with that syntactic sugar can make the code more intuitive.

For this \Soda, has \textbf{object-oriented notation}.
The justification is that humans tend to group and categorize things. % TODO Citation
Humans are used to put things in shelves, drawers, wardrobes, boxes, rooms, etc., and then look for those things where they are supposed to be.
Something similar may happen with functions, and objects capture this idea of having the functions (methods) that are related to them.

This is, of course, an arguable position, since for some people having all functions together seems to be more natural.
The fact of how the most used programming languages have been adopted somehow justifies which preferences were usually considered the most natural.
The structured programming in Pascal was more adopted than the GOTO-based Basic.
The object-oriented C++ and Java became more adopted than plain C.
Many imperative languages, like Java, Python, and C, have functional constructs.

Here are two more things we want in \Soda.
One is to \textbf{limit its expressiveness to help the user}.
In other words, the user is able to essentially express the same things, but making fewer errors.

Another thing is \textbf{minimality}.
The reason beyond that is not only simplify how a specification is written, but also how it is read.
Maybe Prolog would be, from the formalisms considered here, the language with optimal minimality.

We can finally consider Scala\footnote{https://www.scala-lang.org}, which has every single thing we asked for \Soda, except minimality and limits in the expressiveness to avoid errors.

Scala is a statically-typed general-purpose programming language, is multi-paradigm, and fusions object-oriented and functional paradigms.
In this fusion, Scala includes tail recursion, something typical of functional languages, and \scalawhile statement, something typical of imperative languages.
This symbiosis can, unfortunately, lead to mixed programs, which, even for skilled Scala programmers, are difficult to follow.

\Soda is based on a small subset of the purely functional part of Scala, influenced mainly by Haskell and Coq in its design, and in some other aspects, by highly popular languages like Java and Python.

