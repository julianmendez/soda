\chapter{Motivation}

\newcommand{\question}[1]{\textit{#1}}

\newcommand{\comment}[1]{{#1}}


\section{Why - An Itemized Justification}

\begin{itemize}
    \item AI systems can be dangerous, not only at an ethical level
    \item AI systems can be very complex.
    \item Governance can only be achieved by framing and understanding a system.~\cite{doi:10.1145/3278721.3278745}
    \item Communication with computers is formal.
    \item Formal languages are not yet descriptive and resilient to humans, and efficient for computers.
    \item A new descriptive and efficient language would better ensure that AI systems are not dangerous to humans.
\end{itemize}



\textbf{Research Question 1}: How would it be a human-oriented descriptive language used for communication with computers?


\textbf{Research Question 2}: How could ethical values be encoded in such a language?


\textbf{Research Question 3}: How should an ethical verification system integrate that language?

\subsection{AI Systems risks}

AI systems can outperform single or multiple human beings in specific tasks, like massively performed face recognition.
If they are used indulgently, they can threaten human well-being.

\footnote{\url{https://www.cser.ac.uk/research/risks-from-artificial-intelligence/}}
\footnote{\url{https://futureoflife.org/open-letter-autonomous-weapons/}}.
\footnote{\url{https://builtin.com/artificial-intelligence}}

\comment{
    The problem of finding references regarding this is that many (popular) articles are concerned about Artificial General Intelligence.
    From my understanding, we are technologically very far to get there, and the degree of speculation needed makes it difficult to develop a scientifically solid statement.
}

\subsection{AI Systems complexity}

Even it is difficult to define precisely what AI means, it is commonly accepted in the literature that they are complex systems.
\comment{
    The problem here is that it is difficult to find a crystal-clear definition of Artificial Intelligence.
    Some people would think of the \textit{new} artificial intelligence as machine learning, which is not only wrong, but also not conducive to a \textit{more accurate} definition.
    For now, and in the context of this report, AI is either one of two things:
    \begin{itemize}
        \item a very complex computer system
        \item whatever hasn't been done yet. (Larry Tesler's theorem)
    \end{itemize}
}

\subsection{Governance of AI Systems}

This means that it is not enough to have an `off-switch'.
Governance can only be achieved when a system is properly understood by those using it.

When a customer buys a product, and the package is transparent, the customer has more trust than when it is opaque, and only has a nice picture.
The same happens with a system.
It is good if a recognized expert validates how a system works, but it is a lot better if its users can see it by themselves.
Transparency together with governance are not `nice-to-have' properties in a trustable system, they are `must-have' properties.

\subsection{Communication with computers}

It does not matter how beautiful and human-friendly a graphic interface can look,
the communication with a system is through a sequence of 0's and 1's that are interpreted by the computer.
In other words, the human understanding of an approximate explanation, does not apply to computers.
They simulate it, but in the end, everything inside is 0's and 1's.

\comment{
    This is very difficult to \textit{prove}.
    Papers that mention \textit{communication} usually is about \textit{communication protocols} or similar topics.
    This is almost completely unrelated to the human-computer communication.
    There is also Human-Computer Interaction, which focuses on user interfaces (UI) and user experiences (UX).
    However, every interaction is translated to a sequence of events or commands, which can be perfectly described by a computer language.
}

\subsection{Formal languages}

\begin{itemize}
    \item Why is it hard for people to understand other people's code?
    \item Why do people write comments in natural language next to the source code?
    \item Why do developers need a debugging tools at all?
    \item Why cannot most of the people read code as they read a newspaper?
\end{itemize}
The answer to the above questions is simple: source code is not easy to read.
Source code needs to be learned, needs to be practiced, and even with many years, pieces of code can be deceiving.
\footnote{\url{https://www.quora.com/What-are-the-biggest-problems-with-modern-programming-languages}}

It seems that most of the code is written to simplify its parsing by computers, and not for other humans.

This can be since the beginning of computing.
Languages like Fortran, Cobol, and Lisp sought a simplified communication in some sense.
Fortran is to write mathematical formulas, Cobol looks like writing English sentences, Lisp is algebraic.
A long list of programming languages, can prove how hard it is to express things clearly.

Python is probably one of the most popular languages in the direction of achieving being both descriptive and useful.
This point is discussed in the corresponding section.

\comment{
    This is a difficult topic.
    How can I make something better without saying that what is done is worse?
    The answer: every language has its own domain.
    It is difficult to criticize programming languages with long trajectory.
    It is better to give a context for their application.

    \begin{tabular}{lll}
        C
        & pro: efficient and long running                          \\
        & con: difficult to maintain, code can be unreadable       \\
        Python
        & pro: fast prototyping                                    \\
        & con: one never knows where it crashes                    \\
        Java
        & pro: reliable engineering                                \\
        & con: verbose and difficult to read                       \\
        Scala
        & pro: highly flexible and elegant                         \\
        & con: things can be written in a completely illegible way \\
    \end{tabular}

    The list can continue, but how to prove that \textit{none} of the developed languages is \textit{good enough}?
    The answer: by clustering them in groups sharing similar issues.
    The clusters are:
    \begin{itemize}
        \item Dynamically typed languages
        \item Imperative language with mutable values
        \item Highly verbose languages
        \item Languages with very limited expressive power
        \item Languages without classes
        \item Languages without lambda expressions
        \item Non-portable languages
        \item Languages without prototyping
    \end{itemize}

    These clusters capture almost all (if not all) mainstream programming languages, and most of unimplemented formal languages.

    The individual justification of each of the points goes in a different section.
    Some are rather easy (dynamically typed languages). Other are not that easy (highly verbose languages) because they rely in a perception of quality (how much is too much?) rather in an objective principle.

    There are languages that can be distinguished competitors.
    They are:
    \begin{itemize}
        \item Coq: because it can create a program and prove its correctness, which competes with the human checking, and it complements with it. Its code can be exported to Haskell.
        \item Idris: because it is a Haskell dialect based on dependent types. Its programs can be made more reliable than standard Haskell.
        \item Haskell: because it is a long running functional language, with a large community. It is a de-facto standard in functional languages.
        \item Closure: because it is Lisp dialect that runs on the JVM.
        \item Prolog: because it is highly minimalistic. It is language with long trajectory, and widely accepted in the scientific community.
        \item Python: because it is becoming the de-facto standard language in teaching. Many students start with Scratch\footnote{\url{https://scratch.mit.edu/}}, but there is a natural transition to Python. In practice many people will understand Python before any other computer language.
    \end{itemize}

    An important observation that needs to be answered is why relying on humans to understand a program.
    Python is highly readable, and very likely to be a global standard in the following 10 years, but the interpreter does very little verification on the code.
    Coq, on the other side, is a little more difficult to read, but the compiler creates a proof on its code, and it even can be exported to functional languages.
    The new language has to have a readability comparable to Python, but the compiler has to help proving its correctness as much as possible.
    This idea is how a spreadsheet works.
    It is not about challenging the operations done by the computer.
    It is about checking that the calculations are done using the right cells with the right operations.
}

\subsection{A New Language}

A new language is needed, something descriptive and efficient enough.
In this context, `efficient' does not necessary mean that is faster than C, for example.
We mean that its execution or evaluation time in a human scale.
In other words, a human needs to be able to follow what it is written, and determine whether it is right or wrong.
This does not mean that a computer cannot help, but it means that a computer is not needed to understand its operation.
This language needs a way of using it.
This is discussed in the corresponding section.

\comment{
    The approach to prove that a new better language is possible is similar to Cantor's diagonal argument.
    Given a set of constraints that are convenient, i.e. make a language better for ethical purposes, I show that the language here proposed has all those properties.
    Every language in the \textit{bad categories} fails at least one of the constraint.
    Finally, I analyze the \textit{distinguished competitors} one by one, giving sufficient reasons why I prefer not to use them.
}


\section{Why a Language}

To check that an AI system is following ethical principles, it is required to have a system that checks it.

The encoding of ethical values and principles should be reachable to those affected.
If ethical values are encoded in very complex formalisms, they are not reachable to the affected humans, and could be highly error prone.

The purpose of the language is to have formal specifications that can be \textbf{easily understood by a human reader}, and can be immediately prototyped.
This is used to verify if ethical values are properly encoded in a verification system.

Human-centered specifications are intended to be clearly understood by humans.
Please note that this is not necessarily the most abstract form of specification, since a very abstract specification could be hard to understand for the intended reader.

As a rule of thumb, the \textbf{intended reader} is a human that can read a formal specification, probably a second-year undergraduate student of a scientific or engineering course of studies.

There is a marked distinction between the reader and the writer.
In standard formalisms, it is common to find that the gap from reading to writing in that formalism can be small or even trivial.

This is not necessarily the case in the language we are presenting.
The language needs to be very easily understood, although not necessarily very easily written.

The \textbf{intended writer} is then an experienced technician that can model ethical values using the provided constructs, but producing a highly readable description.


\section{Properties for the Language}

This section discusses what kind of language is needed.

The following is a list of properties required for a useful specification language for ethical problems.

At most:
\begin{itemize}
    \item Formal semantics
    \item Consistency
    \item Decidability
\end{itemize}

At least:
\begin{itemize}
    \item Unary predicates, properties or types
    \item Relations or binary predicates
    \item Logical connectors
    \item Distinction and counting
    \item States or time
    \item Specific domains
\end{itemize}


\section{At-most requirements}

\subsection{Formal semantics}

(filter $\leq $)

A formal semantics is intended to give meaning to the language.
This could be used not only to present to humans, but also to prove formal properties on the language.
This allows for rewriting, to have consistency checking and/or formal verification.

(This discards most of the informally developed programming languages.)

\subsection{Consistency}

(filter $\leq $)

The language has to produce consistent specifications.
Consistency is a key property to ensure that a system really follows what is has been specified.
In other words, if a specification is not consistent, it is not usable.

Please note that this requires that descriptions are well-defined.
Some programming languages handle undefined values poorly, letting a program throw an exception when this occurs, instead of preventing it from happening in the first place.

(This property is maybe obvious, but discards unusable formal languages.)

\subsection{Decidability}

(filter $\leq $)

Decidability is intended to ensure that an answer exists and it is computable.
This comes, of course, to a gray area, since decidability has a high price tag by reducing expressivenes.
Thus, the requirement is to have a language with a well defined useful decidable fragment.


\section{At-least requirements}

\subsection{Unary predicates, properties or types}

(filter $\geq $)

Predicates and properties are a very natural way of expressing ideas.
If a formal language does not have them, it becomes more intricate to read.

(This discards low-expressive formalisms, like proposition logic.)

\subsection{Logical connectors}

(filter $\geq $)

The language should include some logical connectors used in natural languages.
Things like \textit{and}, \textit{or}, \textit{not} should be able to be expressed in a direct way.

(This discards many decidable fragments of FOL, like lightweight description logics. )

\subsection{Distinction and counting}

(filter $\geq $)

Expressing distinction is a simple way to count.
Without distinction, there is no way to say ``at least 3 elements''.

Even if it is possible, some formalisms do not provide constructs to do it.
In other words, to say that a set has at least 3 elements, we need to explicitly mention $a, b, c$, and then state
$\{a, b, c\} \subseteq A$, $a \neq b$, $a \neq c$, $b \neq c$.

This grows quadratically in the number of elements.
This is not human friendly, and a construct should be provided, something like $size(A) \geq 3$

(This discards formalisms without counting.)

\subsection{Relations or binary predicates}

(filter $\geq $)

Relating objects is necessary to express basic ideas.
For example, to express that something belongs to someone, it is necessary to relate two elements.
An alternative would be creating separate predicates for each object or for each owner.
This grows linearly in the number of properties (for objects or owners) and it is not human friendly.

(This discards formalisms without relations.)

\subsection{States or time}

(filter $\geq $)

It should be possible to reflect the conceptual idea of time and a sequence.
This means that things happen in a certain order, there is a \textit{before} and an \textit{after}.
In addition, in these transitions, there are \textit{states} associated.
This is a human way of understanding \textit{how things go}.

(This discards formalisms without states.)

\subsection{Specific domains}

(filter $\geq $)

It should be possible to describe things going without modelling them completely.
This means, for example, using operations with floating point, without specifying how floating point works.
When modelling problems, it is reasonable to assume that underlying types would work as expected.

(This discard formalisms that cannot use specific domains / concrete domains.)



