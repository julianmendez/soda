@inproceedings{doi:10.1145/3278721.3278745,
    abstract = {Ethics by Design concerns the methods, algorithms and tools needed to endow autonomous agents with the capability to reason about the ethical aspects of their decisions, and the methods, tools and formalisms to guarantee that an agent's behavior remains within given moral bounds. In this context some questions arise: How and to what extent can agents understand the social reality in which they operate, and the other intelligences (AI, animals and humans) with which they co-exist? What are the ethical concerns in the emerging new forms of society, and how do we ensure the human dimension is upheld in interactions and decisions by autonomous agents?. But overall, the central question is: "Can we, and should we, build ethically-aware agents?" This paper presents initial conclusions from the thematic day of the same name held at PRIMA2017, on October 2017.},
    author = {Dignum, Virginia and Baldoni, Matteo and Baroglio, Cristina and Caon, Maurizio and Chatila, Raja and Dennis, Louise and G\'enova, Gonzalo and Haim, Galit and Klie\ss , Malte S. and Lopez-Sanchez, Maite and Micalizio, Roberto and Pav\'on, Juan and Slavkovik, Marija and Smakman, Matthijs and {Van Steenbergen} , Marlies and Tedeschi, Stefano and {Van Der Toree} , Leon and Villata, Serena and {De Wildt} , Tristan},
    booktitle = {AIES 2018 - Proceedings of the 2018 AAAI/ACM Conference on AI, Ethics, and Society},
    doi = {10.1145/3278721.3278745},
    isbn = {9781450360128},
    keywords = {ACM proceedings,LATEX,text tagging, ethics by design, machine ethics, multi-agent systems},
    title = {{Ethics by Design: Necessity or Curse?}},
    pages = {60--66},
    publisher = {Association for Computing Machinery},
    address = {New York, NY, USA},
    year = {2018},
    month = {12},
    location = {New Orleans, LA, USA},
    series = {{AIES '18}}
}

@article{Casalnuovo2019,
    abstract = {Code corpora, as observed in large software systems, are now known to be far more repetitive and predictable than natural language corpora. But why? Does the difference simply arise from the syntactic limitations of programming languages? Or does it arise from the differences in authoring decisions made by the writers of these natural and programming language texts? We conjecture that the differences are not entirely due to syntax, but also from the fact that reading and writing code is un-natural for humans, and requires substantial mental effort; so, people prefer to write code in ways that are familiar to both reader and writer. To support this argument, we present results from two sets of studies: 1) a first set aimed at attenuating the effects of syntax, and 2) a second, aimed at measuring repetitiveness of text written in other settings (e.g. second language, technical/specialized jargon), which are also effortful to write. We find that this repetition in source code is not entirely the result of grammar constraints, and thus some repetition must result from human choice. While the evidence we find of similar repetitive behavior in technical and learner corpora does not conclusively show that such language is used by humans to mitigate difficulty, it is consistent with that theory. This discovery of “non-syntactic” repetitive behaviour is actionable, and can be leveraged for statistically significant improvements on the code suggestion task. We discuss this finding, and other future implications on practice, and for research.},
    archivePrefix = {arXiv},
    arxivId = {1806.02437},
    author = {Casalnuovo, Casey and Sagae, Kenji and Devanbu, Prem},
    doi = {10.1007/s10664-018-9669-7},
    eprint = {1806.02437},
    issn = {15737616},
    journal = {Empirical Software Engineering},
    keywords = {Corpus comparison,Language modeling,Natural languages,Parse trees,Programming languages,Syntax {\&} grammar},
    title = {{Studying the difference between natural and programming language corpora}},
    year = {2019}
}

@article{Martin2017,
    abstract = {Building upon the success of best-sellers The Clean Coder and Clean Code, legendary software craftsman Robert C. "Uncle Bob" Martin shows how to bring greater professionalism and discipline to application architecture and design. As with his other books, Martin's Clean Architecture doesn't merely present multiple choices and options, and say "use your best judgment": it tells you what choices to make, and why those choices are critical to your success. Martin offers direct, no-nonsense answers to key architecture and design questions like: What are the best high level structures for different kinds of applications, including web, database, thick-client, console, and embedded apps? What are the core principles of software architecture? What is the role of the architect, and what is he/she really trying to achieve? What are the core principles of software design? How do designs and architectures go wrong, and what can you do about it? What are the disciplines and practices of professional architects and designers? Clean Architecture is essential reading for every software architect, systems analyst, system designer, and software manager -- and for any programmer who aspires to these roles or is impacted by their work.},
    archivePrefix = {arXiv},
    arxivId = {arXiv:1011.1669v3},
    author = {Martin, Robert C.},
    eprint = {arXiv:1011.1669v3},
    isbn = {978-0134494166},
    issn = {13563890},
    journal = {Prentice Hall},
    mendeley-groups = {literature/2021/summer{\_}paper},
    pmid = {15991970},
    title = {{Clean Architecture: A Craftsman's Guide to Software Structure and Design}},
    year = {2017}
}

