package scopus.translator

+ org.scalatest.funsuite.AnyFunSuite

+ scala.language.implicitConversions


* TokenizerSpec() extends AnyFunSuite {

  test("should tokenize a small example") {
    input = "    val Constant = \"my text\""
    expected = Seq(
      Token("    val Constant = ", ParserState().Plain, 0),
      Token("\"my text\"", ParserState().QuotesState, 19),
      Token("", ParserState().Plain, 28)
    )
    obtained = Tokenizer().tokenize(input)
    assert(obtained == expected)
  }

  test("should tokenize a common tab in a string") {
    input = "  x = \"abc\tde\""
    expected = Seq(
      Token("  x = ", ParserState().Plain, 0),
      Token("\"abc\tde\"", ParserState().QuotesState, 6),
      Token("", ParserState().Plain, 14)
    )
    obtained = Tokenizer().tokenize(input)
    assert(obtained == expected)
  }

  test("should tokenize an escaped tab in a string") {
    input = "  x = \"abc\\tde\""
    expected = Seq(
      Token("  x = ", ParserState().Plain, 0),
      Token("\"abc\\tde\"", ParserState().QuotesState, 6),
      Token("", ParserState().Plain, 15)
    )
    obtained = Tokenizer().tokenize(input)
    assert(obtained == expected)
  }

  test("should tokenize a single function definition") {
    input = "def f(x: Int): Int = x"
    expected = Seq(
      Token("def f(x: Int): Int = x", ParserState().Plain, 0)
    )
    obtained = Tokenizer().tokenize(input)
    assert(obtained == expected)
  }

  test("should tokenize a function call") {
    input = "\tas_digits (5 * number)"
    expected = Seq(
      Token("\tas_digits (5 * number)", ParserState().Plain, 0)
    )
    obtained = Tokenizer().tokenize(input)
    assert(obtained == expected)
  }


}
