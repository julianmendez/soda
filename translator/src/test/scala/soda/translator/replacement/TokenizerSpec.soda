package soda.translator.replacement


* TokenizerSpec
  extends org.scalatest.funsuite.AnyFunSuite = {

  test("should tokenize a small example") {
    input = "    val Constant = \"my text\""
    expected = Seq(
      Token_("    val Constant = ", ParserStateEnum_().plain, 0),
      Token_("\"my text\"", ParserStateEnum_().quotes_state, 19),
      Token_("", ParserStateEnum_().plain, 28)
    )
    obtained = Tokenizer_(input).tokens

    assert(obtained == expected)
  }

  test("should tokenize a common tab in a string") {
    input = "  x = \"abc\tde\""
    expected = Seq(
      Token_("  x = ", ParserStateEnum_().plain, 0),
      Token_("\"abc\tde\"", ParserStateEnum_().quotes_state, 6),
      Token_("", ParserStateEnum_().plain, 14)
    )
    obtained = Tokenizer_(input).tokens

    assert(obtained == expected)
  }

  test("should tokenize an escaped tab in a string") {
    input = "  x = \"abc\\tde\""
    expected = Seq(
      Token_("  x = ", ParserStateEnum_().plain, 0),
      Token_("\"abc\\tde\"", ParserStateEnum_().quotes_state, 6),
      Token_("", ParserStateEnum_().plain, 15)
    )
    obtained = Tokenizer_(input).tokens

    assert(obtained == expected)
  }

  test("should tokenize a single function definition") {
    input = "def f(x: Int): Int = x"
    expected = Seq(
      Token_("def f(x: Int): Int = x", ParserStateEnum_().plain, 0)
    )
    obtained = Tokenizer_(input).tokens

    assert(obtained == expected)
  }

  test("should tokenize a function call") {
    input = "\tas_digits (5 * number)"
    expected = Seq(
      Token_("\tas_digits (5 * number)", ParserStateEnum_().plain, 0)
    )
    obtained = Tokenizer_(input).tokens

    assert(obtained == expected)
  }
}

* TokenizerSpec_() extends TokenizerSpec

